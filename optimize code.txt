# AI Document Extractor - Consolidated Output Version
# Groups related fields into single rows for cleaner output

# STEP 1: Install Required Libraries
print("üì¶ Installing required libraries...")
!pip install google-generativeai pdfplumber pandas openpyxl -q

# STEP 2: Import Libraries
print("üìö Importing libraries...")
import google.generativeai as genai
import pdfplumber
import pandas as pd
from openpyxl import load_workbook
from openpyxl.styles import Font, Alignment, PatternFill
import json
import re
from typing import List, Dict
from google.colab import files
import io
import time

# CONFIGURATION
class Config:
    def __init__(self, api_key: str):
        self.api_key = api_key
        genai.configure(api_key=api_key)
        print("üîç Setting up Gemini Flash model...")
        self.model = genai.GenerativeModel('gemini-2.5-flash')
        print(f"‚úÖ Using model: gemini-2.5-flash")

# PDF EXTRACTOR
class PDFExtractor:
    def extract_text(self, pdf_file) -> str:
        try:
            with pdfplumber.open(pdf_file) as pdf:
                text_content = []
                for page in pdf.pages:
                    page_text = page.extract_text(layout=True, x_tolerance=3, y_tolerance=3)
                    if page_text:
                        text_content.append(page_text)
                return "\n\n".join(text_content).strip()
        except Exception as e:
            raise Exception(f"PDF extraction failed: {str(e)}")

# DATA CONSOLIDATOR - Groups related fields
class DataConsolidator:
    """Consolidates related fields into single rows"""
    
    @staticmethod
    def consolidate(data: List[Dict]) -> List[Dict]:
        """
        Consolidates related entries:
        - Skill name + rating + experience ‚Üí Single "Skill" row
        - Education degree + institution + year ‚Üí Single "Education" row
        - Certification name + score + year ‚Üí Single "Certification" row
        """
        print("\nüîß Consolidating related fields into single rows...")
        
        consolidated = []
        i = 0
        
        while i < len(data):
            item = data[i]
            key = item.get('key', '').lower()
            
            # Detect skill patterns (skill X name, skill X rating, skill X experience)
            if 'skill' in key and 'name' in key:
                skill_entry = DataConsolidator._consolidate_skill(data, i)
                if skill_entry:
                    consolidated.append(skill_entry)
                    # Skip the consolidated rows
                    i += len([k for k in ['name', 'rating', 'experience', 'context'] 
                             if any(k in data[j].get('key', '').lower() for j in range(i, min(i+5, len(data))))])
                    continue
            
            # Detect certification patterns
            elif 'certification' in key and 'name' in key:
                cert_entry = DataConsolidator._consolidate_certification(data, i)
                if cert_entry:
                    consolidated.append(cert_entry)
                    i += len([k for k in ['name', 'score', 'year', 'rating'] 
                             if any(k in data[j].get('key', '').lower() for j in range(i, min(i+5, len(data))))])
                    continue
            
            # Detect education patterns
            elif 'education' in key or 'degree' in key:
                edu_entry = DataConsolidator._consolidate_education(data, i)
                if edu_entry:
                    consolidated.append(edu_entry)
                    i += len([k for k in ['degree', 'institution', 'year', 'cgpa', 'score'] 
                             if any(k in data[j].get('key', '').lower() for j in range(i, min(i+7, len(data))))])
                    continue
            
            # Detect job/role patterns
            elif any(term in key for term in ['job', 'role', 'position']) and ('title' in key or 'designation' in key):
                job_entry = DataConsolidator._consolidate_job(data, i)
                if job_entry:
                    consolidated.append(job_entry)
                    i += len([k for k in ['title', 'company', 'start', 'end', 'salary'] 
                             if any(k in data[j].get('key', '').lower() for j in range(i, min(i+7, len(data))))])
                    continue
            
            # Keep as-is if not part of a group
            consolidated.append(item)
            i += 1
        
        # Renumber
        for idx, item in enumerate(consolidated, 1):
            item['#'] = idx
        
        print(f"‚úÖ Consolidated: {len(data)} rows ‚Üí {len(consolidated)} rows (reduced by {len(data) - len(consolidated)})")
        return consolidated
    
    @staticmethod
    def _consolidate_skill(data: List[Dict], start_idx: int) -> Dict:
        """Combine skill name + rating + experience into one row"""
        skill_data = {}
        comments = []
        
        # Look ahead up to 4 rows for related skill fields
        for j in range(start_idx, min(start_idx + 5, len(data))):
            key = data[j].get('key', '').lower()
            value = data[j].get('value', '')
            comment = data[j].get('comments', '').strip()
            
            if 'skill' in key:
                if 'name' in key:
                    skill_data['name'] = value
                elif 'rating' in key or 'proficiency' in key:
                    skill_data['rating'] = value
                elif 'experience' in key:
                    skill_data['experience'] = value
                elif 'context' in key:
                    skill_data['context'] = value
                
                if comment and comment not in comments:
                    comments.append(comment)
            else:
                break  # Stop if we hit a non-skill field
        
        if skill_data.get('name'):
            parts = []
            if 'name' in skill_data:
                parts.append(skill_data['name'])
            if 'rating' in skill_data:
                parts.append(f"(Rating: {skill_data['rating']})")
            if 'experience' in skill_data:
                parts.append(f"- Experience: {skill_data['experience']}")
            if 'context' in skill_data:
                parts.append(f"- {skill_data['context']}")
            
            return {
                '#': start_idx + 1,
                'key': f"Skill: {skill_data['name']}",
                'value': ' '.join(parts),
                'comments': ' '.join(comments) if comments else ''
            }
        return None
    
    @staticmethod
    def _consolidate_certification(data: List[Dict], start_idx: int) -> Dict:
        """Combine certification fields"""
        cert_data = {}
        comments = []
        
        for j in range(start_idx, min(start_idx + 5, len(data))):
            key = data[j].get('key', '').lower()
            value = data[j].get('value', '')
            comment = data[j].get('comments', '').strip()
            
            if 'certification' in key:
                if 'name' in key:
                    cert_data['name'] = value
                elif 'score' in key or 'rating' in key:
                    cert_data['score'] = value
                elif 'year' in key:
                    cert_data['year'] = value
                
                if comment and comment not in comments:
                    comments.append(comment)
            else:
                break
        
        if cert_data.get('name'):
            parts = [cert_data['name']]
            if 'score' in cert_data:
                parts.append(f"- Score: {cert_data['score']}")
            if 'year' in cert_data:
                parts.append(f"(Year: {cert_data['year']})")
            
            return {
                '#': start_idx + 1,
                'key': f"Certification: {cert_data['name']}",
                'value': ' '.join(parts),
                'comments': ' '.join(comments) if comments else ''
            }
        return None
    
    @staticmethod
    def _consolidate_education(data: List[Dict], start_idx: int) -> Dict:
        """Combine education fields"""
        edu_data = {}
        comments = []
        
        for j in range(start_idx, min(start_idx + 7, len(data))):
            key = data[j].get('key', '').lower()
            value = data[j].get('value', '')
            comment = data[j].get('comments', '').strip()
            
            if any(term in key for term in ['education', 'degree', 'school', 'college', 'university', 'cgpa', 'grade']):
                if 'degree' in key or 'standard' in key:
                    edu_data['degree'] = value
                elif 'institution' in key or 'school' in key or 'college' in key or 'university' in key:
                    edu_data['institution'] = value
                elif 'year' in key:
                    edu_data['year'] = value
                elif 'cgpa' in key or 'gpa' in key or 'score' in key or 'percentage' in key:
                    edu_data['grade'] = value
                elif 'rank' in key:
                    edu_data['rank'] = value
                
                if comment and comment not in comments:
                    comments.append(comment)
            else:
                break
        
        if edu_data.get('degree') or edu_data.get('institution'):
            parts = []
            if 'degree' in edu_data:
                parts.append(edu_data['degree'])
            if 'institution' in edu_data:
                parts.append(f"from {edu_data['institution']}")
            if 'year' in edu_data:
                parts.append(f"(Year: {edu_data['year']})")
            if 'grade' in edu_data:
                parts.append(f"- Grade: {edu_data['grade']}")
            if 'rank' in edu_data:
                parts.append(f"- Rank: {edu_data['rank']}")
            
            return {
                '#': start_idx + 1,
                'key': f"Education: {edu_data.get('degree', 'Qualification')}",
                'value': ' '.join(parts),
                'comments': ' '.join(comments) if comments else ''
            }
        return None
    
    @staticmethod
    def _consolidate_job(data: List[Dict], start_idx: int) -> Dict:
        """Combine job/role fields"""
        job_data = {}
        comments = []
        
        for j in range(start_idx, min(start_idx + 7, len(data))):
            key = data[j].get('key', '').lower()
            value = data[j].get('value', '')
            comment = data[j].get('comments', '').strip()
            
            if any(term in key for term in ['job', 'role', 'position', 'designation', 'company', 'organization', 'salary']):
                if 'title' in key or 'designation' in key:
                    job_data['title'] = value
                elif 'company' in key or 'organization' in key:
                    job_data['company'] = value
                elif 'start' in key or 'joining' in key:
                    job_data['start'] = value
                elif 'end' in key:
                    job_data['end'] = value
                elif 'salary' in key:
                    job_data['salary'] = value
                
                if comment and comment not in comments:
                    comments.append(comment)
            else:
                break
        
        if job_data.get('title'):
            parts = [job_data['title']]
            if 'company' in job_data:
                parts.append(f"at {job_data['company']}")
            if 'start' in job_data:
                parts.append(f"(Started: {job_data['start']})")
            if 'salary' in job_data:
                parts.append(f"- Salary: {job_data['salary']}")
            
            return {
                '#': start_idx + 1,
                'key': f"Role: {job_data['title']}",
                'value': ' '.join(parts),
                'comments': ' '.join(comments) if comments else ''
            }
        return None

# AI AGENT
class AIAgent:
    def __init__(self, model):
        self.model = model
    
    def extract_key_values(self, text: str) -> List[Dict]:
        prompt = f"""Extract ALL information from this text into a JSON array. Each item needs: "key", "value", "comments".

IMPORTANT INSTRUCTIONS:
1. Extract 100% of the content - every fact, number, date, name
2. Use EXACT original wording in the "value" field
3. Create separate entries for EACH piece of information
4. Keep comments concise - only add when providing useful context

Example output format:
[
{{"key": "first name", "value": "Vijay", "comments": "Person's details"}},
{{"key": "birth date", "value": "March 15, 1989", "comments": "ISO format: 1989-03-15"}},
{{"key": "skill 1 name", "value": "SQL expertise", "comments": "Technical proficiency details"}},
{{"key": "skill 1 rating", "value": "10 out of 10", "comments": ""}},
{{"key": "skill 1 experience", "value": "daily usage since 2012", "comments": ""}}
]

TEXT TO EXTRACT:
{text}

Return ONLY the JSON array:"""
        
        max_retries = 3
        for attempt in range(max_retries):
            try:
                print(f"ü§ñ Extracting data (Attempt {attempt + 1}/{max_retries})...")
                
                response = self.model.generate_content(
                    prompt,
                    generation_config={'temperature': 0.1, 'max_output_tokens': 8192}
                )
                
                response_text = response.text
                print(f"üìù Received {len(response_text)} characters")
                
                json_data = self._extract_json(response_text)
                
                if json_data and len(json_data) > 0:
                    print(f"‚úÖ Parsed {len(json_data)} items")
                    for idx, item in enumerate(json_data, 1):
                        item['#'] = idx
                    return json_data
                
            except Exception as e:
                print(f"‚ö†Ô∏è  Attempt {attempt + 1} failed: {str(e)}")
                if attempt < max_retries - 1:
                    time.sleep(5)
        
        raise Exception("Extraction failed after retries")
    
    def _extract_json(self, text: str) -> List[Dict]:
        text = re.sub(r'```json\s*', '', text)
        text = re.sub(r'```\s*', '', text)
        text = text.strip()
        
        json_match = re.search(r'\[.*\]', text, re.DOTALL)
        if json_match:
            data = json.loads(json_match.group(0))
            if isinstance(data, list):
                valid_data = []
                for item in data:
                    if isinstance(item, dict):
                        cleaned = {
                            'key': str(item.get('key', item.get('Key', ''))),
                            'value': str(item.get('value', item.get('Value', ''))),
                            'comments': str(item.get('comments', item.get('Comments', item.get('comment', ''))))
                        }
                        if cleaned['key'] or cleaned['value']:
                            valid_data.append(cleaned)
                return valid_data
        raise Exception("No valid JSON found")

# EXCEL GENERATOR
class ExcelGenerator:
    def create_excel(self, data: List[Dict], output_filename: str = "Output.xlsx"):
        df = pd.DataFrame(data)
        df = df.rename(columns={'#': '#', 'key': 'Key', 'value': 'Value', 'comments': 'Comments'})
        
        columns = ['#', 'Key', 'Value', 'Comments']
        for col in columns:
            if col not in df.columns:
                df[col] = ''
        
        df = df[columns]
        print(f"üìä Creating Excel with {len(df)} rows")
        
        df.to_excel(output_filename, index=False, sheet_name='Extracted Data')
        self._apply_formatting(output_filename)
        print(f"‚úÖ Excel created: {output_filename}")
    
    def _apply_formatting(self, excel_path: str):
        wb = load_workbook(excel_path)
        ws = wb.active
        
        header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
        header_font = Font(bold=True, color="FFFFFF", size=11)
        
        for cell in ws[1]:
            cell.fill = header_fill
            cell.font = header_font
            cell.alignment = Alignment(horizontal='center', vertical='center')
        
        ws.column_dimensions['A'].width = 8
        ws.column_dimensions['B'].width = 45
        ws.column_dimensions['C'].width = 50
        ws.column_dimensions['D'].width = 80
        
        for row in ws.iter_rows(min_row=2, max_row=ws.max_row):
            for cell in row:
                cell.alignment = Alignment(vertical='top', wrap_text=True)
        
        ws.freeze_panes = 'A2'
        wb.save(excel_path)

# MAIN
def main():
    print("="*60)
    print("üöÄ AI DOCUMENT EXTRACTOR - CONSOLIDATED VERSION")
    print("   ‚úì Groups related fields into single rows")
    print("   ‚úì Cleaner, more readable output")
    print("="*60)
    
    api_key = input("\nEnter Gemini API Key: ").strip()
    if not api_key:
        return
    
    print("\nüì§ Upload PDF file...")
    uploaded = files.upload()
    if not uploaded:
        return
    
    pdf_filename = list(uploaded.keys())[0]
    pdf_content = uploaded[pdf_filename]
    
    try:
        config = Config(api_key)
        pdf_extractor = PDFExtractor()
        ai_agent = AIAgent(config.model)
        consolidator = DataConsolidator()
        excel_generator = ExcelGenerator()
        
        print("\nüìÑ Extracting PDF text...")
        raw_text = pdf_extractor.extract_text(io.BytesIO(pdf_content))
        print(f"‚úÖ Extracted {len(raw_text)} characters")
        
        print("\nü§ñ AI extracting data...")
        structured_data = ai_agent.extract_key_values(raw_text)
        
        print("\nüîß Consolidating related fields...")
        consolidated_data = consolidator.consolidate(structured_data)
        
        print("\nüìä Generating Excel...")
        excel_generator.create_excel(consolidated_data, "Output.xlsx")
        
        print("\nüíæ Downloading...")
        files.download("Output.xlsx")
        
        print("\n‚úÖ COMPLETE!")
        print(f"   ‚Ä¢ Original entries: {len(structured_data)}")
        print(f"   ‚Ä¢ Consolidated: {len(consolidated_data)}")
        print(f"   ‚Ä¢ Saved {len(structured_data) - len(consolidated_data)} rows!")
        
    except Exception as e:
        print(f"\n‚ùå Error: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()